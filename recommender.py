# -*- coding: utf-8 -*-
"""Recommender.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1KMthvrdqIxDQPGDRxW8N-UAOFrXKKiut

# Recommender System

#### Dataset
- [Kaggle Dataset](https://www.kaggle.com/datasets/arashnic/book-recommendation-dataset)
"""

# import libraries
import numpy as np
import pandas as pd
from sklearn.metrics.pairwise import cosine_similarity

# to ignore warinings
import warnings
warnings.filterwarnings('ignore')

# import data
books = pd.read_csv('Data/Books.csv')  # books data
users = pd.read_csv('Data/Users.csv') # Users location and age data
ratings = pd.read_csv('Data/Ratings.csv') # Users rating data

books.head()

users.head()

ratings.head()

books.shape

ratings.shape

users.shape

# Looking of nulls in books data
books.isnull().sum()

# Brop the nulls
books = books.dropna()

# Looking of nulls in books data
books.isnull().sum()

# Looking of nulls in books data
users.isnull().sum()

users = users.dropna()

# Looking of nulls in books data
users.isnull().sum()

# Looking of nulls in books data
ratings.isnull().sum()

books.shape

users.shape

ratings.shape

# Checking of duplicates
books.duplicated().sum()

# Checking of duplicates
users.duplicated().sum()

# Checking of duplicates
ratings.duplicated().sum()

# Unique count
books.nunique()

users.head()

ratings.head()

np.sort(ratings['Book-Rating'].unique())

books.info()

books.columns

# convert year of publication to int
books['Year-Of-Publication'] = books['Year-Of-Publication'].astype('int32')

books.info()

ratings.info()

users.info()



"""## Popularity Based Recommender System"""

books.head()

ratings.head()

users.head()

# Joining books and user ratings into one table
books_with_ratings = ratings.merge(books, on = 'ISBN')

books_with_ratings.head()

books_with_ratings.shape

popular_df = books_with_ratings.groupby('Book-Title').agg(num_rating=('Book-Rating', 'count'),
                                                         avg_rating= ('Book-Rating','mean'))

popular_df = popular_df.reset_index()

popular_df

popular_df.sort_values('num_rating',ascending=False)

# Popularity is based on the no of people read the book  ('num_raitng' > 300)
# It is based on the rating it got.
popular_df = popular_df[popular_df['num_rating']>300].sort_values('avg_rating', ascending=False)

popular_df

popular_df = popular_df.head(50)

popular_df

# For the model deployment I need Book-title, Author, Image URL
popular_df = popular_df.merge(books, on = 'Book-Title').drop_duplicates('Book-Title')[['Book-Title',
                                                                                       'Book-Author',
                                                                                       'Image-URL-M',
                                                                                       'num_rating',
                                                                                      'avg_rating']]

popular_df

"""### Colaborative Filtering
- Similar book prediction based on users feedback
"""

books_with_ratings.head()

# Grouping based on user-id tells the no of books rated by each user:
x = books_with_ratings.groupby('User-ID').count()
x

x.index

x.shape

# Select only users who atleast gave feed back for 200 books (Power users )
x = x['Book-Rating'] > 200
x

power_users = x[x].index

power_users

power_users.shape

power_users.sort_values()

# selecting only records of power users
filtered_ratings = books_with_ratings[books_with_ratings['User-ID'].isin(power_users)]

filtered_ratings

# I am cosidering only the best users (atleast 200 books feedback) group them based on the book title.
y = filtered_ratings.groupby('Book-Title').count()

y

# The above dataframe tell how many users have read the book.
y.sort_values('User-ID',ascending=False)

y = y['User-ID'] >= 50

y

famous_books = y[y].index

famous_books

final_ratings = filtered_ratings[filtered_ratings['Book-Title'].isin(famous_books)]

final_ratings

# pivot table giving the ratings for each book from each user
# Book row with userid as column
pt = final_ratings.pivot_table(index='Book-Title', columns='User-ID',values='Book-Rating')

pt

pt = pt.fillna(0)

pt

similarity_scores = cosine_similarity(pt)

similarity_scores

type(similarity_scores)

df_temp = pd.DataFrame(similarity_scores)

df_temp

pt.index

def recommend(book_name):
    index = np.where(pt.index == book_name)[0][0]
    similar_items = sorted(list(enumerate(similarity_scores[index])), key=lambda x : x[1], reverse=True)[1:6]
    # Lets create empty list and in that lies i want ot populate with the book information
    # Book author book-title image url
    # Empty list
    data = []
    for i in similar_items:
        item = []
        temp_df = books[books['Book-Title'] == pt.index[i[0]]]
        item.extend(list(temp_df.drop_duplicates('Book-Title')['Book-Title'].values))
        item.extend(list(temp_df.drop_duplicates('Book-Title')['Book-Author'].values))
        item.extend(list(temp_df.drop_duplicates('Book-Title')['Image-URL-M'].values))
        data.append(item)
    return data

recommend('1984')

books.columns

recommend('Animal Farm')

pt.index[0]

"""# Export Data and model to pkl"""

# Import Pickle and dump the data and models
import pickle as pkl
pkl.dump(popular_df,open('popular.pkl','wb')) # Popularity based recommender system

pkl.dump(books,open('books.pkl','wb')) # book data
pkl.dump(pt,open('pt.pkl','wb')) # books and user feedback
pkl.dump(similarity_scores, open('similarity_scores.pkl','wb'))



















